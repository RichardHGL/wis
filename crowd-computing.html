---
layout: default_style
title: Crowd Computing & Human-Centered AI
---

<section id="{{page.team}}" class="section-global-wrapper">
    <div class="container content-space">
        <div class="row justify-content-center blog-post">
            <h2>{{page.title}}</h2>
        </div>

        <div class="row">
            <div class="row blog-post">
                <div class="col-md-3">
                    <img src="{{site.baseurl}}/assets/img/theme/kappa_HAII.jpg"
                         alt="Add a picture that represents the team" width="100%"/>
                </div>

                <div class="col-md-9 vertical-align-text">
                    <p>We focus on core areas which are instrumental in developing the next generation of AI systems â€“
                        (1) Human-in-the-loop AI, (2) Human-AI interaction, (3) User Modeling and Explainability.
                        Our work considers the computational role of humans for AI, i.e., AI by humans, and the
                        interactional role of humans with AI systems, i.e., AI for humans.</p>
                </div>
            </div>
        </div>


        <!--If more than 2 topics are present in your team, please add a new row.-->

        <div class="row">
            <div class="col-md-6">
                <div class="row justify-content-center blog-post">
                    <h3>Human-in-the-loop AI</h3>
                </div>

                <div class="row justify-content-center">
                    <p> Machine learning models have been criticized for the lack of robustness, fairness, and
                        transparency.
                        For models to learn comprehensive,
                        fine-grained, and unbiased patterns, they have to be trained on a large number of high-quality
                        data instances with the
                        right distribution that is representative of real application scenarios. Creating such data is
                        not only a long, laborious,
                        and expensive process, but sometimes even impossible.
                        In this theme, we analyze the fundamental computational challenges in the quest for robust,
                        interpretable, and trustworthy AI systems.
                        We argue that to tackle such fundamental challenges, research should explore a novel crowd
                        computing paradigm where diverse and distributed crowds
                        can contribute knowledge at the conceptual level.
                    </p>
                </div>
            </div>

            <div class="col-md-6">
                <div class="row justify-content-center blog-post">
                    <h3>Human-AI Interaction</h3>
                </div>
                <div class="row justify-content-center">
                    <p>In the light of recent advances in AI and the growing role of AI technologies in human-centered
                        applications,
                        a deeper exploration of interaction between humans and machines is the need of the hour.
                        Within this theme of Human-AI interaction, we will explore and develop fundamental
                        methods and techniques to harness the virtues of AI in a manner that is beneficial and useful to
                        the society at large.
                        From the interaction perspective, more robust and interpretable systems can help build trust and
                        increase system uptake.
                        As AI systems become more commonplace, people must be able to make sense of their encounters and
                        interpret their interactions with such systems.
                    </p>
                </div>
            </div>


            <div class="col-md-12">
                <div class="row justify-content-center blog-post">
                    <h3>User Modeling & Explainability</h3>
                </div>
                <div class="row justify-content-center">
                    <p>As algorithmic decision-making becomes prevalent across many sectors it is important to help
                        users understand why certain decisions
                        are being proposed. Explanations are needed when there is a large knowledge gap between human
                        and AI or information systems, or when joint understanding
                        is only implicit. This type of joint understanding is becoming increasingly important for
                        example when news providers, and social media systems
                        such as Twitter and Facebook, filter and rank the information that people see. To link the
                        mental models of both systems and people our work
                        develops ways to supply users with a level of transparency and control that is meaningful and
                        useful to them. We develop methods for generating
                        and interpreting rich meta-data that helps bridge the gap between computational and human
                        reasoning (e.g., for understanding subjective concepts
                        such as diversity and credibility). We also develop a theoretical framework for generating
                        better explanations (as both text and interactive
                        explanation interfaces), which adapts to a user and their context. To better understand the
                        conditions for explanation effectiveness,
                        we look at when to explain (e.g., surprising content, lean in/lean out, risk, complexity); and
                        what to adapt to (e.g., group dynamics,
                        personal characteristics of a user).
                    </p>
                </div>
            </div>

        </div>

        <!--The list of people is AUTOMATICALLY computed-->
        <div class="row">
            <h3 class="col-md-12 blog-post">People</h3>
            <div class="col-md-12 margin-left-3">
                {% include filter-people.html team='kappa' %}
            </div>
        </div>

        <!--The list of projects is automatically retrieved from _data/kappa.yml -->
        <!--Please fill in the yml file with the data about your projects. -->
        <div class="row">
            <h3 class="col-md-12 blog-post">Projects</h3>
            <ul class="col-md-12">
                {% for project in site.data.kappa.projects %}
                <li class="margin-left-3">
                    <h5><a href="{{project.link}}" target="_blank"> {{project.title}}</a></h5>
                    <p>{{project.description}}</p>
                </li>
                {% endfor %}
            </ul>
        </div>


        <!--Create link to PURE to retrieve the publications -->
        <div class="row">
            <h2 class="col-md-12 blog-post">Publications</h2>
            <ul class="col-md-12">
                <li class="margin-left-3">
                    List of publications
                </li>
            </ul>
        </div>
    </div>
</section>

